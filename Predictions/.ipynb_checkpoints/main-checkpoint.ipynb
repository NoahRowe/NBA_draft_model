{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a01e03f3",
   "metadata": {},
   "source": [
    "This is the main notebook that will generate predictions for new players with no targets. The process is as follows:\n",
    "- Import formatted data for new draftees\n",
    "- Import formatted data for old draftees for training\n",
    "- Train a model (or multiple models) on the old data\n",
    "- Generate predictions (or multiple predictions) for the new players\n",
    "- Summarize these predictions in an easy to understand graphic / table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d11cadb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import pairwise\n",
    "\n",
    "import preds_helper as helper\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8cc151c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import old dataset for training\n",
    "X, Y = helper.load_training_data()\n",
    "\n",
    "# Import NBA players histories\n",
    "NBAdata = helper.getNBAdata()\n",
    "\n",
    "# Import new player data\n",
    "draftees = helper.load_draftee_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a53c1bda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define training variables\n",
    "clusteringCols = ['FT%', '3P%', 'eFG%', 'ORB%', 'DRB%', 'AST%', 'TOV%', 'STL%', 'BLK%', 'USG%', 'OWS', 'DWS', \n",
    "                  'FTA', '3PA', 'PTS', 'PF', 'MP_per_PF', 'FTA_per_FGA', 'MP_per_3PA', 'PTS_per_FGA', \n",
    "                  'C', 'F', 'G', 'PPM', 'PPG', 'HEIGHT', 'WEIGHT']\n",
    "\n",
    "x_cols = ['gamesPlayed', 'minutes', 'FT%', '3P%', 'SOS', 'PER', 'eFG%', 'ORB%', 'DRB%', 'AST%', 'TOV%', \n",
    "          'STL%', 'BLK%', 'USG%','OWS', 'DWS', 'FTA', 'FGA', 'MP', '3PA', 'PTS', 'PF', 'MP_per_PF', 'PPG', \n",
    "          'PPM','FTA_per_FGA', 'MP_per_3PA', 'PTS_per_FGA', \"AST_per_TOV\", 'ORtg', 'DRtg','awards','RSCI', \n",
    "          'm1', 'm2', 'm3', 'm4', 'm5', 'm6', 'SHUTTLE_RUN','THREE_QUARTER_SPRINT', 'STANDING_VERTICAL', \n",
    "          'MAX_VERTICAL','BENCH_PRESS', 'BODY_FAT', 'HAND_LENGTH', 'HAND_WIDTH', \"didCombine\", \n",
    "          'HEIGHT_W_SHOES', 'REACH', 'WEIGHT', 'WINGSPAN', 'C', 'F', 'G']\n",
    "target = \"WM\"\n",
    "allCols = list(dict.fromkeys(clusteringCols + x_cols)) # removes duplicates\n",
    "draftOnlyCols = [col for col in allCols if col not in clusteringCols]\n",
    "\n",
    "with open('../Model/cluster_scaler.pkl', 'rb') as f:\n",
    "    c_scaler = pickle.load(f)\n",
    "with open('../Model/draft_scaler.pkl', 'rb') as f:\n",
    "    d_scaler = pickle.load(f)\n",
    "\n",
    "scaledDraft, scaledNBA = draftees.copy(), NBAdata.copy()\n",
    "scaledDraft[clusteringCols] = c_scaler.transform(scaledDraft[clusteringCols])\n",
    "scaledDraft[draftOnlyCols] = d_scaler.transform(scaledDraft[draftOnlyCols])\n",
    "scaledNBA[clusteringCols] = c_scaler.transform(scaledNBA[clusteringCols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6634601f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do the clustering\n",
    "n_clusters =  3\n",
    "with open('../Model/cluster_model.pkl', 'rb') as f:\n",
    "    fittedCluster = pickle.load(f)\n",
    "scaledNBA['label'] = fittedCluster.predict(scaledNBA[clusteringCols].values, sample_weight=None)\n",
    "scaledDraft['label'] = fittedCluster.predict(scaledDraft[clusteringCols].values, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c60d9476",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a function that will get features for all draftees for each team\n",
    "metricCols, metric, n_players = clusteringCols, \"manhattan\", 7\n",
    "metric_function = pairwise.distance_metrics()[metric]\n",
    "\n",
    "nba_features = ['dist_avg', \"dist_std\", \"dist_dot_min\", \"dist_dot_WS\", \"min_dist\", \"label_count\"]\n",
    "# Closest we have to current raptors lineup\n",
    "raptors = ['Pascal Siakam', 'Kyle Lowry', 'Norman Powell', 'Aron Baynes', \"DeAndre' Bembry\", \"Stanley Johnson\", \n",
    "        \"Patrick McCaw\"]\n",
    "teamSize = len(raptors)\n",
    "\n",
    "teamData = scaledNBA[scaledNBA.Player.isin(raptors)].groupby(\"Player\").mean()\n",
    "#teamData.loc[\"Kyle Lowry\"][\"label\"] = 0\n",
    "teamData['label'] = teamData['label'].astype(int)\n",
    "\n",
    "def getTeamFeatures(draftee):\n",
    "    \n",
    "    preds = pd.DataFrame(columns=nba_features, index=[draftee['Player']])\n",
    "\n",
    "    distances = [metric_function(draftee[metricCols].to_numpy().reshape(1,-1), \n",
    "                                 teamData.loc[player][metricCols].to_numpy().reshape(1,-1)).item()\n",
    "                 for player in raptors]\n",
    "    # Turn them into a feature vector\n",
    "    preds[\"dist_avg\"] = np.mean(distances)\n",
    "    preds[\"dist_std\"] = np.std(distances)\n",
    "    preds[\"dist_dot_min\"] = np.dot(distances, teamData[\"MP\"].values)\n",
    "    preds[\"dist_dot_WS\"] = np.dot(distances, teamData[\"MP\"].values)\n",
    "    preds[\"min_dist\"] = np.min(distances)\n",
    "    labelPlayerCount = len(teamData[teamData['label']==draftee[\"label\"]])\n",
    "    preds[\"label_count\"] = labelPlayerCount/teamSize\n",
    "\n",
    "    return preds\n",
    "        \n",
    "# Create a dictionary containing {draftee name:team features df}\n",
    "teamFeatures = []\n",
    "for i in range(len(scaledDraft)):\n",
    "    draftee = scaledDraft.iloc[i]\n",
    "    drafteeName = draftee[\"Player\"]\n",
    "    teamFeatures.append(getTeamFeatures(draftee))\n",
    "    #print(\"{}/{} completed!\".format(i+1, len(scaledDraft)))\n",
    "\n",
    "    \n",
    "# Scale these features\n",
    "teamFeatures = pd.concat(teamFeatures)\n",
    "with open('../Model/team_features_scaler.pkl', 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "\n",
    "#df = pd.DataFrame(scaler.transform(teamFeatures[nba_features]), index=teamFeatures.index, columns=nba_features)\n",
    "teamFeatures[nba_features] = scaler.transform(teamFeatures[nba_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b7ea3af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Change what our training subset looks like \n",
    "allCols = list(dict.fromkeys(allCols)) # removes duplicate\n",
    "trainingCols = allCols + nba_features\n",
    "\n",
    "# Add the actual features (for training the model) to the overall dataset\n",
    "for col in nba_features: scaledDraft[col] = np.nan\n",
    "for i in range(len(scaledDraft)):\n",
    "    player = scaledDraft.iloc[i][\"Player\"]\n",
    "    for c in nba_features:\n",
    "        scaledDraft.iloc[i, scaledDraft.columns.get_loc(c)] = teamFeatures.loc[player][c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "09045328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/100 Completed\n",
      "1/100 Completed\n",
      "2/100 Completed\n",
      "3/100 Completed\n",
      "4/100 Completed\n",
      "5/100 Completed\n",
      "6/100 Completed\n",
      "7/100 Completed\n",
      "8/100 Completed\n",
      "9/100 Completed\n",
      "10/100 Completed\n",
      "11/100 Completed\n",
      "12/100 Completed\n",
      "13/100 Completed\n",
      "14/100 Completed\n",
      "15/100 Completed\n",
      "16/100 Completed\n",
      "17/100 Completed\n",
      "18/100 Completed\n",
      "19/100 Completed\n",
      "20/100 Completed\n",
      "21/100 Completed\n",
      "22/100 Completed\n",
      "23/100 Completed\n",
      "24/100 Completed\n",
      "25/100 Completed\n",
      "26/100 Completed\n",
      "27/100 Completed\n",
      "28/100 Completed\n",
      "29/100 Completed\n",
      "30/100 Completed\n",
      "31/100 Completed\n",
      "32/100 Completed\n",
      "33/100 Completed\n",
      "34/100 Completed\n",
      "35/100 Completed\n",
      "36/100 Completed\n",
      "37/100 Completed\n",
      "38/100 Completed\n",
      "39/100 Completed\n",
      "40/100 Completed\n",
      "41/100 Completed\n",
      "42/100 Completed\n",
      "43/100 Completed\n",
      "44/100 Completed\n",
      "45/100 Completed\n",
      "46/100 Completed\n",
      "47/100 Completed\n",
      "48/100 Completed\n",
      "49/100 Completed\n",
      "50/100 Completed\n",
      "51/100 Completed\n",
      "52/100 Completed\n",
      "53/100 Completed\n",
      "54/100 Completed\n",
      "55/100 Completed\n",
      "56/100 Completed\n",
      "57/100 Completed\n",
      "58/100 Completed\n",
      "59/100 Completed\n",
      "60/100 Completed\n",
      "61/100 Completed\n",
      "62/100 Completed\n",
      "63/100 Completed\n",
      "64/100 Completed\n",
      "65/100 Completed\n",
      "66/100 Completed\n",
      "67/100 Completed\n",
      "68/100 Completed\n",
      "69/100 Completed\n",
      "70/100 Completed\n",
      "71/100 Completed\n",
      "72/100 Completed\n",
      "73/100 Completed\n",
      "74/100 Completed\n",
      "75/100 Completed\n",
      "76/100 Completed\n",
      "77/100 Completed\n",
      "78/100 Completed\n",
      "79/100 Completed\n",
      "80/100 Completed\n",
      "81/100 Completed\n",
      "82/100 Completed\n",
      "83/100 Completed\n",
      "84/100 Completed\n",
      "85/100 Completed\n",
      "86/100 Completed\n",
      "87/100 Completed\n",
      "88/100 Completed\n",
      "89/100 Completed\n",
      "90/100 Completed\n",
      "91/100 Completed\n",
      "92/100 Completed\n",
      "93/100 Completed\n",
      "94/100 Completed\n",
      "95/100 Completed\n",
      "96/100 Completed\n",
      "97/100 Completed\n",
      "98/100 Completed\n",
      "99/100 Completed\n"
     ]
    }
   ],
   "source": [
    "# Do the actual loop to get predicted values\n",
    "preds = pd.DataFrame(index=scaledDraft.Player)\n",
    "\n",
    "itters = 100\n",
    "\n",
    "# Train and test it multiple times to average results\n",
    "for i in range(itters):\n",
    "    model = helper.create_NN()\n",
    "    X, Y = X.sample(frac=1), Y.sample(frac=1)\n",
    "\n",
    "    # Convert the input to tensors\n",
    "    #X_train = tf.convert_to_tensor(X[trainingCols], dtype=tf.float32)\n",
    "    #Y_train = tf.convert_to_tensor(Y[target], dtype=tf.float32)\n",
    "\n",
    "    #X_raptors = tf.convert_to_tensor(scaledDraft[trainingCols])\n",
    "\n",
    "    # Train the model\n",
    "    #model.fit(X_train, Y_train)\n",
    "    model.fit(X.to_numpy(), Y.to_numpy())\n",
    "\n",
    "    # Generate predictions\n",
    "#     preds[f\"{i}\"] = model.predict(X_raptors)\n",
    "    preds[f\"{i}\"] = model.predict(scaledDraft[trainingCols])\n",
    "    print(f\"{i}/{itters} Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "817bb11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(index=preds.index)\n",
    "results['avg_pred'] = [np.mean(preds.loc[player]) for player in preds.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2ad14fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avg_pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Player</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>matthewmayer</th>\n",
       "      <td>1.191207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joewieskamp</th>\n",
       "      <td>1.186065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ochaiagbaji</th>\n",
       "      <td>1.185991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yvespons</th>\n",
       "      <td>1.183238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tremann</th>\n",
       "      <td>1.183115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jerichosims</th>\n",
       "      <td>1.181601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kessleredwards</th>\n",
       "      <td>1.181369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aaronwiggins</th>\n",
       "      <td>1.173553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>justinchampagnie</th>\n",
       "      <td>1.172272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>davionmitchell</th>\n",
       "      <td>1.168521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kaijones</th>\n",
       "      <td>1.168497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joshchristopher</th>\n",
       "      <td>1.165025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nahshonhyland</th>\n",
       "      <td>1.164970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jamesbouknight</th>\n",
       "      <td>1.162229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jaredbutler</th>\n",
       "      <td>1.159384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ziairewilliams</th>\n",
       "      <td>1.157385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moseswright</th>\n",
       "      <td>1.155787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marcuszegarowski</th>\n",
       "      <td>1.155414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>charlesbassey</th>\n",
       "      <td>1.155279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jadenspringer</th>\n",
       "      <td>1.153445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carlikjones</th>\n",
       "      <td>1.152518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ayodosunmu</th>\n",
       "      <td>1.151589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joshuaprimo</th>\n",
       "      <td>1.150557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marcusbagley</th>\n",
       "      <td>1.148326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scottielewis</th>\n",
       "      <td>1.146347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sandromamukelashvili</th>\n",
       "      <td>1.145272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quentingrimes</th>\n",
       "      <td>1.144684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>julianchampagnie</th>\n",
       "      <td>1.142136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>milesmcbride</th>\n",
       "      <td>1.140139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>samhauser</th>\n",
       "      <td>1.139839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>johnnyjuzang</th>\n",
       "      <td>1.139619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jasonpreston</th>\n",
       "      <td>1.138433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isaiahlivers</th>\n",
       "      <td>1.138425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jtthor</th>\n",
       "      <td>1.137755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neemiasqueta</th>\n",
       "      <td>1.136375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxabmas</th>\n",
       "      <td>1.135923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>djsteward</th>\n",
       "      <td>1.135819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dayronsharpe</th>\n",
       "      <td>1.127945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>austinreaves</th>\n",
       "      <td>1.119237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cadecunningham</th>\n",
       "      <td>1.118599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trendonwatford</th>\n",
       "      <td>1.113856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jalenjohnson</th>\n",
       "      <td>1.112751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>isaiahmobley</th>\n",
       "      <td>1.112630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mosesmoody</th>\n",
       "      <td>1.112611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>scottiebarnes</th>\n",
       "      <td>1.102751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raiquangray</th>\n",
       "      <td>1.096021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coreykispert</th>\n",
       "      <td>1.091979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lukagarza</th>\n",
       "      <td>1.091054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ajlawson</th>\n",
       "      <td>1.090476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sharifecooper</th>\n",
       "      <td>1.084597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>makurmaker</th>\n",
       "      <td>1.015717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      avg_pred\n",
       "Player                        \n",
       "matthewmayer          1.191207\n",
       "joewieskamp           1.186065\n",
       "ochaiagbaji           1.185991\n",
       "yvespons              1.183238\n",
       "tremann               1.183115\n",
       "jerichosims           1.181601\n",
       "kessleredwards        1.181369\n",
       "aaronwiggins          1.173553\n",
       "justinchampagnie      1.172272\n",
       "davionmitchell        1.168521\n",
       "kaijones              1.168497\n",
       "joshchristopher       1.165025\n",
       "nahshonhyland         1.164970\n",
       "jamesbouknight        1.162229\n",
       "jaredbutler           1.159384\n",
       "ziairewilliams        1.157385\n",
       "moseswright           1.155787\n",
       "marcuszegarowski      1.155414\n",
       "charlesbassey         1.155279\n",
       "jadenspringer         1.153445\n",
       "carlikjones           1.152518\n",
       "ayodosunmu            1.151589\n",
       "joshuaprimo           1.150557\n",
       "marcusbagley          1.148326\n",
       "scottielewis          1.146347\n",
       "sandromamukelashvili  1.145272\n",
       "quentingrimes         1.144684\n",
       "julianchampagnie      1.142136\n",
       "milesmcbride          1.140139\n",
       "samhauser             1.139839\n",
       "johnnyjuzang          1.139619\n",
       "jasonpreston          1.138433\n",
       "isaiahlivers          1.138425\n",
       "jtthor                1.137755\n",
       "neemiasqueta          1.136375\n",
       "maxabmas              1.135923\n",
       "djsteward             1.135819\n",
       "dayronsharpe          1.127945\n",
       "austinreaves          1.119237\n",
       "cadecunningham        1.118599\n",
       "trendonwatford        1.113856\n",
       "jalenjohnson          1.112751\n",
       "isaiahmobley          1.112630\n",
       "mosesmoody            1.112611\n",
       "scottiebarnes         1.102751\n",
       "raiquangray           1.096021\n",
       "coreykispert          1.091979\n",
       "lukagarza             1.091054\n",
       "ajlawson              1.090476\n",
       "sharifecooper         1.084597\n",
       "makurmaker            1.015717"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values(by=\"avg_pred\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a120e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
